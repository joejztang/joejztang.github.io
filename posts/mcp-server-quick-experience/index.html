<!doctype html><html lang=en><head><title>mcp server quick experience · 130l</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=color-scheme content="light dark"><meta name=author content="130l"><meta name=description content="I was wondering about mcp server for long time, and finally I gave it a quick try.

  idea about what to &ldquo;mcp&rdquo;
  
    
    Link to heading
  

There are many mcp out there, doing all kinds of tasks. For example, there is a nice curated repo here that you can find all kinds of mcp servers.
But what should I start with my own mcp server experience? I wondered long. Finally I spotted on something that LLM historically doesn&rsquo;t do well: calculations."><meta name=keywords content="blog,science,technology,personal"><meta name=twitter:card content="summary"><meta name=twitter:title content="mcp server quick experience"><meta name=twitter:description content="I was wondering about mcp server for long time, and finally I gave it a quick try.
idea about what to “mcp” Link to heading There are many mcp out there, doing all kinds of tasks. For example, there is a nice curated repo here that you can find all kinds of mcp servers.
But what should I start with my own mcp server experience? I wondered long. Finally I spotted on something that LLM historically doesn’t do well: calculations."><meta property="og:url" content="https://joejztang.github.io/posts/mcp-server-quick-experience/"><meta property="og:site_name" content="130l"><meta property="og:title" content="mcp server quick experience"><meta property="og:description" content="I was wondering about mcp server for long time, and finally I gave it a quick try.
idea about what to “mcp” Link to heading There are many mcp out there, doing all kinds of tasks. For example, there is a nice curated repo here that you can find all kinds of mcp servers.
But what should I start with my own mcp server experience? I wondered long. Finally I spotted on something that LLM historically doesn’t do well: calculations."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-10-19T16:40:12-07:00"><meta property="article:modified_time" content="2025-10-19T16:40:12-07:00"><meta property="article:tag" content="Mcp"><link rel=canonical href=https://joejztang.github.io/posts/mcp-server-quick-experience/><link rel=preload href=/fonts/fa-brands-400.woff2 as=font type=font/woff2 crossorigin><link rel=preload href=/fonts/fa-regular-400.woff2 as=font type=font/woff2 crossorigin><link rel=preload href=/fonts/fa-solid-900.woff2 as=font type=font/woff2 crossorigin><link rel=stylesheet href=/css/coder.min.4b392a85107b91dbdabc528edf014a6ab1a30cd44cafcd5325c8efe796794fca.css integrity="sha256-SzkqhRB7kdvavFKO3wFKarGjDNRMr81TJcjv55Z5T8o=" crossorigin=anonymous media=screen><link rel=stylesheet href=/css/coder-dark.min.a00e6364bacbc8266ad1cc81230774a1397198f8cfb7bcba29b7d6fcb54ce57f.css integrity="sha256-oA5jZLrLyCZq0cyBIwd0oTlxmPjPt7y6KbfW/LVM5X8=" crossorigin=anonymous media=screen><link rel=icon type=image/svg+xml href=/img/favicon.svg sizes=any><link rel=icon type=image/png href=/img/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/img/favicon-16x16.png sizes=16x16><link rel=apple-touch-icon href=/images/apple-touch-icon.png><link rel=apple-touch-icon sizes=180x180 href=/images/apple-touch-icon.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/images/safari-pinned-tab.svg color=#5bbad5></head><body class="preload-transitions colorscheme-auto"><div class=float-container><a id=dark-mode-toggle class=colorscheme-toggle><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></a></div><main class=wrapper><nav class=navigation><section class=container><a class=navigation-title href=https://joejztang.github.io/>130l
</a><input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><i class="fa-solid fa-bars fa-fw" aria-hidden=true></i></label><ul class=navigation-list><li class=navigation-item><a class=navigation-link href=/posts/>Posts</a></li><li class=navigation-item><a class=navigation-link href=/about/>About</a></li></ul></section></nav><div class=content><section class="container post"><article><header><div class=post-title><h1 class=title><a class=title-link href=https://joejztang.github.io/posts/mcp-server-quick-experience/>mcp server quick experience</a></h1></div><div class=post-meta><div class=date><span class=posted-on><i class="fa-solid fa-calendar" aria-hidden=true></i>
<time datetime=2025-10-19T16:40:12-07:00>October 19, 2025
</time></span><span class=reading-time><i class="fa-solid fa-clock" aria-hidden=true></i>
2-minute read</span></div><div class=categories><i class="fa-solid fa-folder" aria-hidden=true></i>
<a href=/categories/ai/>Ai</a>
<span class=separator>•</span>
<a href=/categories/machine-learning/>Machine Learning</a></div><div class=tags><i class="fa-solid fa-tag" aria-hidden=true></i>
<span class=tag><a href=/tags/mcp/>Mcp</a></span></div></div></header><div class=post-content><p>I was wondering about mcp server for long time, and finally I gave it a quick try.</p><h1 id=idea-about-what-to-mcp>idea about what to &ldquo;mcp&rdquo;
<a class=heading-link href=#idea-about-what-to-mcp><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h1><p>There are many mcp out there, doing all kinds of tasks. For example, there is a nice curated repo <a href="https://github.com/punkpeye/awesome-mcp-servers?tab=readme-ov-file#text-to-speech" class=external-link target=_blank rel=noopener>here</a> that you can find all kinds of mcp servers.</p><p>But what should I start with my own mcp server experience? I wondered long. Finally I spotted on something that LLM historically doesn&rsquo;t do well: calculations.</p><p>Don&rsquo;t get me wrong, LLM nowadays can do calculations - even for complicated math problems. But if you remember, it used to be not able to compare which one is larger: 3.9 or 3.11. This problem let me believe that maybe I don&rsquo;t want to trust LLM to do calculation, and I want to trust programming language more to do that.</p><p>MCP server provides the bridging.</p><h1 id=the-server>the server
<a class=heading-link href=#the-server><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h1><p><a href=https://github.com/joejztang/math-mcp class=external-link target=_blank rel=noopener>here</a> is the repo.</p><h2 id=references-during-the-developing>references during the developing
<a class=heading-link href=#references-during-the-developing><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><ul><li><a href="https://github.com/modelcontextprotocol/typescript-sdk?tab=readme-ov-file#with-session-management" class=external-link target=_blank rel=noopener>mcp server sdk repo</a></li><li><a href=https://brightdata.com/blog/ai/sse-vs-streamable-http class=external-link target=_blank rel=noopener>sse vs streamable</a></li><li><a href="https://www.youtube.com/watch?v=nTPeM8l3zTg" class=external-link target=_blank rel=noopener>video explaning simple mcp server (including streamable and inspector)</a></li></ul><h1 id=issues-when-developing>issues when developing
<a class=heading-link href=#issues-when-developing><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h1><ol><li>timing out after connect successfully to claude ai. Still I dont know why, but different client has different temper. Eventually it works with github copilot.</li></ol><h1 id=streamable-over-sse>streamable over sse
<a class=heading-link href=#streamable-over-sse><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h1><p>Key improvements of Streamable HTTP over SSE</p><ul><li>Single endpoint: Unlike the older SSE model that required separate endpoints, Streamable HTTP uses a single endpoint for both client requests and server responses.</li><li>Bidirectional communication: It enables real-time bidirectional streaming through a unified protocol, allowing both client and server to send messages on the same connection.</li><li>Compatibility: It maintains compatibility with standard HTTP infrastructure by operating over plain HTTP, making it suitable for use with various middleware and serverless platforms.</li><li>Resilience: It includes features like session resume on drops, which improves reliability compared to the traditional SSE model.</li><li>Flexibility: It can use SSE as an efficient mechanism for streaming, making it a hybrid approach that combines the strengths of both protocols.</li></ul><h1 id=further-thoughts>further thoughts
<a class=heading-link href=#further-thoughts><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h1><p>People are saying it&rsquo;s a wrapper of apis, which sounds like true according to my quick experience. However it does provide a decoupled way connecting APIs with LLM. Don&rsquo;t know what will be changing in the future, but it&rsquo;s something we need to keep an eye on.</p></div><footer><div class=comments><script>let getTheme=window.localStorage&&window.localStorage.getItem("colorscheme"),themeInParams="github-light";getTheme==null&&(themeInParams!==""&&themeInParams!=="auto"?getTheme=themeInParams:getTheme=window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light");let theme=getTheme==="dark"?"github-dark":"github-light",s=document.createElement("script");s.src="https://utteranc.es/client.js",s.setAttribute("repo","joejztang/joejztang.github.io"),s.setAttribute("issue-term","pathname"),s.setAttribute("theme",theme),s.setAttribute("crossorigin","anonymous"),s.setAttribute("async",""),document.querySelector("div.comments").innerHTML="",document.querySelector("div.comments").appendChild(s)</script></div></footer></article></section></div><footer class=footer><section class=container>©
1990 -
2025
130l
·
Powered by <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> & <a href=https://github.com/luizdepra/hugo-coder/ target=_blank rel=noopener>Coder</a>.</section></footer></main><script src=/js/coder.min.6ae284be93d2d19dad1f02b0039508d9aab3180a12a06dcc71b0b0ef7825a317.js integrity="sha256-auKEvpPS0Z2tHwKwA5UI2aqzGAoSoG3McbCw73gloxc="></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-YNPYVVT1S7"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-YNPYVVT1S7")}</script></body></html>