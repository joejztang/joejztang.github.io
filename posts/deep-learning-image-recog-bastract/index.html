<!doctype html><html lang=en><head><title>deep learning image recognization abstract · 130l</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=color-scheme content="light dark"><meta name=author content="130l"><meta name=description content="this post is mainly focus on image recognizaton.

  traslation invariance
  
    
    Link to heading
  

neural network will recognize traditional images for sure. but what if our target image is very small and at the left top corner?
in this case, neural network will not be so helpful.

when a machine learning model can recognize an object no matter whether it is moved (or translated) in the image."><meta name=keywords content="blog,science,technology,personal"><meta name=twitter:card content="summary"><meta name=twitter:title content="deep learning image recognization abstract"><meta name=twitter:description content="this post is mainly focus on image recognizaton.
traslation invariance Link to heading neural network will recognize traditional images for sure. but what if our target image is very small and at the left top corner?
in this case, neural network will not be so helpful.
when a machine learning model can recognize an object no matter whether it is moved (or translated) in the image."><meta property="og:url" content="http://www.example.com/posts/deep-learning-image-recog-bastract/"><meta property="og:site_name" content="130l"><meta property="og:title" content="deep learning image recognization abstract"><meta property="og:description" content="this post is mainly focus on image recognizaton.
traslation invariance Link to heading neural network will recognize traditional images for sure. but what if our target image is very small and at the left top corner?
in this case, neural network will not be so helpful.
when a machine learning model can recognize an object no matter whether it is moved (or translated) in the image."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2019-10-02T14:33:30+00:00"><meta property="article:modified_time" content="2019-10-02T14:33:30+00:00"><meta property="article:tag" content="Keras"><meta property="article:tag" content="Tensorflow"><link rel=canonical href=http://www.example.com/posts/deep-learning-image-recog-bastract/><link rel=preload href=/fonts/fa-brands-400.woff2 as=font type=font/woff2 crossorigin><link rel=preload href=/fonts/fa-regular-400.woff2 as=font type=font/woff2 crossorigin><link rel=preload href=/fonts/fa-solid-900.woff2 as=font type=font/woff2 crossorigin><link rel=stylesheet href=/css/coder.min.4b392a85107b91dbdabc528edf014a6ab1a30cd44cafcd5325c8efe796794fca.css integrity="sha256-SzkqhRB7kdvavFKO3wFKarGjDNRMr81TJcjv55Z5T8o=" crossorigin=anonymous media=screen><link rel=stylesheet href=/css/coder-dark.min.a00e6364bacbc8266ad1cc81230774a1397198f8cfb7bcba29b7d6fcb54ce57f.css integrity="sha256-oA5jZLrLyCZq0cyBIwd0oTlxmPjPt7y6KbfW/LVM5X8=" crossorigin=anonymous media=screen><link rel=icon type=image/svg+xml href=/img/favicon.svg sizes=any><link rel=icon type=image/png href=/img/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/img/favicon-16x16.png sizes=16x16><link rel=apple-touch-icon href=/images/apple-touch-icon.png><link rel=apple-touch-icon sizes=180x180 href=/images/apple-touch-icon.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/images/safari-pinned-tab.svg color=#5bbad5></head><body class="preload-transitions colorscheme-auto"><div class=float-container><a id=dark-mode-toggle class=colorscheme-toggle><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></a></div><main class=wrapper><nav class=navigation><section class=container><a class=navigation-title href=http://www.example.com/>130l
</a><input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><i class="fa-solid fa-bars fa-fw" aria-hidden=true></i></label><ul class=navigation-list><li class=navigation-item><a class=navigation-link href=/posts/>Posts</a></li><li class=navigation-item><a class=navigation-link href=/about/>About</a></li></ul></section></nav><div class=content><section class="container post"><article><header><div class=post-title><h1 class=title><a class=title-link href=http://www.example.com/posts/deep-learning-image-recog-bastract/>deep learning image recognization abstract</a></h1></div><div class=post-meta><div class=date><span class=posted-on><i class="fa-solid fa-calendar" aria-hidden=true></i>
<time datetime=2019-10-02T14:33:30Z>October 2, 2019
</time></span><span class=reading-time><i class="fa-solid fa-clock" aria-hidden=true></i>
2-minute read</span></div><div class=categories><i class="fa-solid fa-folder" aria-hidden=true></i>
<a href=/categories/deep-learning/>Deep Learning</a></div><div class=tags><i class="fa-solid fa-tag" aria-hidden=true></i>
<span class=tag><a href=/tags/keras/>Keras</a>
</span><span class=separator>•</span>
<span class=tag><a href=/tags/tensorflow/>Tensorflow</a></span></div></div></header><div class=post-content><p>this post is mainly focus on image recognizaton.</p><h2 id=traslation-invariance>traslation invariance
<a class=heading-link href=#traslation-invariance><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>neural network will recognize traditional images for sure. but what if our target image is very small and at the left top corner?</p><p>in this case, neural network will not be so helpful.</p><blockquote><p>when a machine learning model can recognize an object no matter whether it is moved (or <em>translated</em>) in the image.</p></blockquote><p>above called <code>translation invariance</code>.</p><p>we introduce <code>convolutional layer</code>.</p><p><code>convolutional layer</code> will break image into small overlapping tiles, passing each tiles to neural network. in this time, the output would be array.</p><p>after done, we changes set of weights on the nodes. because we changing the weights, nodes will look different pattern than first time.</p><p>repeat above again and again, it forms a 3D array. this 3D array will be passed to next layer of neural network, and it will use this info to decide which patterns are most important.</p><p>there could be more than one <code>convolutional layers</code>.</p><h2 id=maxpooling>maxpooling
<a class=heading-link href=#maxpooling><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>idea of <code>maxpooling</code> is to down sample the data by only passing on the most important bits.</p><p>for example:</p><p><img src=/images/maxpooling.PNG alt=maxpooling></p><h2 id=dropout>dropout
<a class=heading-link href=#dropout><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p><code>dropout</code> is to solve the problem that neural network tend to memorize the input instead actually learning it.</p><p><code>dropout</code> layer will randomly throw away some of the data by cutting some of the connections.</p><h2 id=convolutional-block>convolutional block
<a class=heading-link href=#convolutional-block><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p><code>convolutional layer</code> + <code>maxpooling layer</code> + <code>dropout layer</code> = <code>convolutional block</code></p><p><code>convolutional block</code> is a standard method.</p><h2 id=image-recognition-models>image recognition models
<a class=heading-link href=#image-recognition-models><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><ul><li>VGG</li><li>ResNet-50</li><li>Inception v3</li><li>MobileNet</li><li>NASNet</li></ul><h2 id=transfer-learning>transfer learning
<a class=heading-link href=#transfer-learning><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p><img src=/images/predicting-w-transfer-learning.PNG alt="transfer learning"></p><p>the essence of <code>transfer learning</code> is to reuse the <code>convolutional layers</code> and then create our own <code>dense layer</code> to train.</p><p>because in <code>convolutional layers</code>, they will capture all the patterns, and we don&rsquo;t want to start from scratch, so we just send those patterns to new dense layer to tell neural network what new it is.</p><p>if from scratch, it is more like teaching baby to read and then recognize something, but if we reuse <code>convolutional layers</code>, it is more like ask an adult that already know how to read and just tell him what it is.</p></div><footer></footer></article></section></div><footer class=footer><section class=container>©
1990 -
2025
130l
·
Powered by <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> & <a href=https://github.com/luizdepra/hugo-coder/ target=_blank rel=noopener>Coder</a>.</section></footer></main><script src=/js/coder.min.6ae284be93d2d19dad1f02b0039508d9aab3180a12a06dcc71b0b0ef7825a317.js integrity="sha256-auKEvpPS0Z2tHwKwA5UI2aqzGAoSoG3McbCw73gloxc="></script></body></html>