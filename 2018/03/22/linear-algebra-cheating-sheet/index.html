<!DOCTYPE html><html lang="en"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="migrating to raspberry server"><title>linear algebra cheating sheet | 130L blog</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/normalize.css/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.jsdelivr.net/npm/jquery/dist/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-118615339-1','auto');ga('send','pageview');
</script><script type="text/javascript" src="//cdn.jsdelivr.net/npm/clipboard/dist/clipboard.min.js"></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.js"></script><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.css"><meta name="generator" content="Hexo 5.2.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">linear algebra cheating sheet</h1><a id="logo" href="/.">130L blog</a><p class="description">Cogito, ergo sum</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">linear algebra cheating sheet</h1><div class="post-meta">2018-03-22<span> | </span><span class="category"><a href="/categories/math/">Math</a><a href="/categories/math/linear-algebra/">Linear Algebra</a></span></div><a class="disqus-comment-count" data-disqus-identifier="2018/03/22/linear-algebra-cheating-sheet/" href="/2018/03/22/linear-algebra-cheating-sheet/#disqus_thread"></a><div class="post-content"><p>This cheating sheet is only computer/Machine Learning/Deep Learning wise.</p>
<p>I have read <a target="_blank" rel="noopener" href="http://tutorial.math.lamar.edu/">Paul Dawkin</a>‘s previous contents and accumulated some gists that I found useful. (content seems not to be there anymore, for more infomation, please contact the author)</p>
<a id="more"></a>

<h2 id="inverse-matrices-and-elementary-matrices"><a href="#inverse-matrices-and-elementary-matrices" class="headerlink" title="inverse matrices and elementary matrices"></a>inverse matrices and elementary matrices</h2><ul>
<li><p>If \(A\) is a square matrix and we can find another matrix of the same size, say \(B\), such that</p>
<p> \[ AB = BA = I \]</p>
<p> then we call \(A\) invertible and we say that \(B\) is an inverse of the matrix \(A\). If we can’t find such a matrix \(B\) we call A a singular matrix.</p>
</li>
<li><p>Suppose that \(A\) and \(B\) are invertible matrices of the same size. Then, </p>
<p><strong>(a)</strong> \(AB\) is invertible and \( {(AB)}^{−1} = {B}^{−1}{A}^{−1} \).</p>
<p><strong>(b)</strong> \({A}^{−1}\) is invertible and \( {({A}^{−1})}^{-1} =A\).</p>
<p><strong>(c)</strong> For \( n=0,1,2,… {A}^n \) is invertible and \( {({A}^n)}^{-1} = {A}^{−n} ={(A^{−1})}^n \).</p>
<p><strong>(d)</strong> If \(c\) is any non-zero scalar then \(cA\) is invertible and \( {(cA)}^{−1} = {1 \over c} {A}^{−1} \)<br><strong>(e)</strong> \(A^T\) is invertible and \( {(A^T)}^{-1} = {(A^{−1})}^T \).</p>
</li>
</ul>
<h3 id="elementary-matrix"><a href="#elementary-matrix" class="headerlink" title="elementary matrix"></a>elementary matrix</h3><ul>
<li>A square matrix is called an <strong>elementary matrix</strong> if it can be obtained by applying a single elementary row operation to the identity matrix of the same size.</li>
</ul>
<h2 id="finding-inverse-matrices"><a href="#finding-inverse-matrices" class="headerlink" title="finding inverse matrices"></a>finding inverse matrices</h2><ul>
<li><p>If \(A\) is an \(n \times n\) matrix then the following statements are equivalent. </p>
<p><strong>(a)</strong> \(A\) is invertible.</p>
<p><strong>(b)</strong> The only solution to the system \(A \mathbf{x} = 0\) is the trivial solution. </p>
<p><strong>(c)</strong> \(A\) is row equivalent to \(I_n\).</p>
<p><strong>(d)</strong> \(A\) is expressible as a product of elementary matrices.</p>
<p><strong>(e)</strong> \(A \mathbf{x} = \mathbf{b} \) has exactly one solution for every \(n \times 1\) matrix \(\mathbf{b}\). </p>
<p><strong>(f)</strong> \(A \mathbf{x} = \mathbf{b} \) is consistent for every \(n \times 1\) matrix \(\mathbf{b}\).</p>
<p><strong>(g)</strong> \( det(A) \ne 0 \).</p>
</li>
</ul>
<h3 id="consistent-and-inconsistent"><a href="#consistent-and-inconsistent" class="headerlink" title="consistent and inconsistent"></a>consistent and inconsistent</h3><p>  A system of linear equations is called <strong>inconsistent</strong> if it has no solutions. A system which has a solution is called <strong>consistent</strong>.</p>
<h2 id="Special-Matrices"><a href="#Special-Matrices" class="headerlink" title="Special Matrices"></a>Special Matrices</h2><ul>
<li><p>About triangular matrix</p>
<p><strong>(a)</strong> The product of lower triangular matrices will be a lower triangular matrix. </p>
<p><strong>(b)</strong> The product of upper triangular matrices will be an upper triangular matrix. </p>
<p><strong>(c)</strong> The inverse of an invertible lower triangular matrix will be a lower triangular matrix.</p>
<p><strong>(d)</strong> The inverse of an invertible upper triangular matrix will be an upper triangular matrix.</p>
</li>
<li><p>About symmetric matrix</p>
<p><strong>(a)</strong> For any matrix \(A\) both \(AA^T\) and \(A^T A\) are symmetric.</p>
<p><strong>(b)</strong> If \(A\) is an invertible symmetric matrix then \(A^{−1}\) is symmetric. </p>
<p><strong>(c)</strong> If \(A\) is invertible then \(AA^T\) and \(A^T A\) are both invertible.</p>
</li>
</ul>
<h2 id="Determinants"><a href="#Determinants" class="headerlink" title="Determinants"></a>Determinants</h2><ul>
<li><p>Let \(A\) be an \(n \times n\) matrix and \(c\) be a scalar then,<br>\[det(cA)=c^n det(A)\]</p>
</li>
<li><p>If \(A\) and \(B\) are matrices of the same size then<br>\[ det(AB)=det(A)det(B) \]</p>
</li>
<li><p>Suppose that \(A\) is an invertible matrix then,<br>\[ det(A^{−1})= {1 \over det(A)} \]</p>
</li>
</ul>
<h3 id="singular-and-non-singular"><a href="#singular-and-non-singular" class="headerlink" title="singular and non-singular"></a>singular and non-singular</h3><ul>
<li><p>A square matrix A is invertible if and only if \( det (A) \ne 0 \) . A matrix that is<br>invertible is often called <strong>non-singular</strong> and a matrix that is not invertible is often called <strong>singular</strong>.</p>
</li>
<li><p>If A is a square matrix then, \( det(A)=det(A^T) \).</p>
</li>
<li><p>Suppose that \(A\) is an \(n \times n\) triangular matrix then, \( det(A)= a11\ a22\ …\ ann \).</p>
</li>
</ul>
<h2 id="adjoint"><a href="#adjoint" class="headerlink" title="adjoint"></a>adjoint</h2><h3 id="matrix-of-cofactors-from-A-Adjoint-of-A"><a href="#matrix-of-cofactors-from-A-Adjoint-of-A" class="headerlink" title="matrix of cofactors from A, Adjoint of A"></a>matrix of cofactors from A, Adjoint of A</h3><p>If \(A\) is a square matrix then the minor of \(a_{ij}\), </p>
<p>denoted by \(M_{ij}\)</p>
<p> is the determinant of the submatrix that results from removing the \(i^{th}\) row and \(j^{th}\) column of \(A\). If \(A\) is a square matrix then the <strong>cofactor of \(a_{ij}\)</strong> </p>
<p>denoted by \(C_{ij}\) </p>
<p>is the number \((−1)^{i+j} M_{ij}\) .</p>
<ul>
<li>Let \(A\) be an n×n matrix and \(C_{ij}\) </li>
</ul>
<p>be the cofactor of \(a_{ij}\). The <strong>matrix of cofactors from A</strong> is,</p>
<p>\begin{bmatrix}<br>C11 &amp; C12 &amp; … &amp; C1n\\<br>C21 &amp; C22 &amp; … &amp; C2n\\<br>\vdots &amp; \vdots &amp; \ddots &amp; \vdots\\<br>Cn1 &amp; Cn2 &amp; … &amp; Cnn<br>\end{bmatrix}</p>
<p>The <strong>adjoint of A</strong> is the transpose of the matrix of cofactors and is denoted by adj(A).</p>
<ul>
<li><p>If A is an invertible matrix then<br>\[ A^{−1} = {1 \over det(A)}adj(A) \]</p>
</li>
<li><p>Let A be a square matrix.</p>
<p><strong>(a)</strong> If \(B\) is the matrix that results from multiplying a row or column of \(A\) by a<br>scalar, \(c\), then \( det(B)= cdet(A)\)</p>
<p><strong>(b)</strong> If \(B\) is the matrix that results from interchanging two rows or two columns of<br>\(A\) then \(det(B)=−det(A)\)</p>
<p><strong>(c)</strong> If \(B\) is the matrix that results from adding a multiple of one row of \(A\) onto another row of \(A\) or adding a multiple of one column of \(A\) onto another column of \(A\) then \(det(B)=det(A)\)</p>
</li>
</ul>
<h2 id="Cramer’s-Rule"><a href="#Cramer’s-Rule" class="headerlink" title="Cramer’s Rule"></a>Cramer’s Rule</h2><p>Suppose that \(A\) is an \(n \times n\) invertible matrix. Then the solution to the system<br>\(Ax=b\) is given by,</p>
<p>\[ x_1 = { det(A_1) \over det(A) }, x_2 = { det(A_2) \over det(A) }, …, x_n = { det(A_n) \over det(A) } \]</p>
<p>where \(A_i\) is the matrix found by replacing the \(i^{th}\) column of \(A\) with \(\mathbf{b}\).</p>
<h2 id="Euclidean-n-space"><a href="#Euclidean-n-space" class="headerlink" title="Euclidean n-space"></a>Euclidean n-space</h2><ul>
<li><p>Two non-zero vectors, <strong>u</strong> and <strong>v</strong>, are orthogonal if and only if \({u} \centerdot {v} = 0 \)</p>
</li>
<li><p>Suppose that \(u\) and \(a \ne 0\) are both vectors in 2-space or 3-space then,</p>
</li>
</ul>
<p>\[proj_a \mathbf{u} = { {\mathbf{u} \centerdot \mathbf{a} } \over {\parallel \mathbf{a} \parallel}^2 } \mathbf{a}\]</p>
<p>and the vector component of <strong>u</strong> orthogonal to <strong>a</strong> is given by,</p>
<p>\[\mathbf{u} - proj_a \mathbf{u} = {\mathbf{u}- {\mathbf{u} \centerdot \mathbf{a} } \over {\parallel \mathbf{a} \parallel}^2 } \mathbf{a}\]</p>
<ul>
<li><p>If u and v are two vectors in 3-space then the cross product, denoted by u × v and is defined in one of three ways.</p>
<p><strong>(a)</strong> \( \mathbf{u} \times \mathbf{v} = (u_2v_3 −u_3v_2,u_3v_1 −u_1v_3,u_1v_2 −u_2v_1) \)-Vector Notation.</p>
<p><strong>(b)</strong> \( \mathbf{u} \times \mathbf{v} = (\begin{vmatrix} u_2 &amp; u_3 \\ v_2 &amp; v_3\end{vmatrix}, -\begin{vmatrix} u_1 &amp; u_3 \\ v_1 &amp; v_3\end{vmatrix}, \begin{vmatrix} u_1 &amp; u_2 \\ v_1 &amp; v_2\end{vmatrix}) \) - Using 2 x 2 determinants</p>
<p><strong>(c)</strong> \( \mathbf{u} \times \mathbf{v} = \begin{vmatrix} \mathbf{i} &amp; \mathbf{j} &amp; \mathbf{k}\\ u_1 &amp; u_2 &amp; u_3\\ v_1 &amp; v_2 &amp; v_3\end{vmatrix} \) - Using 3 x 3 determinants</p>
</li>
<li><p>The cross product <strong>a × b</strong> is defined as a vector <strong>c</strong> that is perpendicular (orthogonal) to both a and <strong>b</strong>, with a direction given by the right-hand rule and a magnitude equal to the area of the parallelogram that the vectors span.</p>
</li>
<li><p>Suppose \(\mathbf{u}, \mathbf{v}\), and \(\mathbf{w}\) are vectors in 3-space and \(c\) is any scalar then </p>
<p><strong>(a)</strong> \( \mathbf{u×v=−(v×u)} \)</p>
<p><strong>(b)</strong> \( \mathbf{u×(v+w)=(u×v)+(u×w)} \)</p>
<p><strong>(c)</strong> \( \mathbf{(u+v)×w=(u×w)+(v×w)} \)</p>
<p><strong>(d)</strong> \( c\mathbf{(u×v)}=(c\mathbf{u})×\mathbf{v}=\mathbf{u}×(c\mathbf{v}) \)</p>
<p><strong>(e)</strong> \( \mathbf{u×0=0×u=0} \) </p>
<p><strong>(f)</strong> \( \mathbf{u×u=0} \)</p>
</li>
</ul>
<h3 id="lagrange-identity"><a href="#lagrange-identity" class="headerlink" title="lagrange identity"></a>lagrange identity</h3><ul>
<li><p>Suppose \( \mathbf{u, v} \), and \( \mathbf{w} \) are vectors in 3-space then, </p>
<p><strong>(a)</strong> \( \mathbf{u \centerdot (u×v)=0} \)</p>
<p><strong>(b)</strong> \( \mathbf{v \centerdot (u×v)=0} \)</p>
<p><strong>(c)</strong> \( {\parallel \mathbf{u \times v} \parallel}^2 = {\parallel \mathbf{u} \parallel}^2\ {\parallel \mathbf{v} \parallel}^2 −{\mathbf{(u \centerdot v)}}^2 \) - This is called <strong>Lagrange’s Identity</strong> </p>
<p><strong>(d)</strong> \( \mathbf{ u \times (v \times w)=(u \centerdot w)v−(u \centerdot v)w } \)</p>
<p><strong>(e)</strong> \( \mathbf{(u \times v) \times w=(u \centerdot w)v−(v \centerdot w)u} \)</p>
</li>
<li><p>Suppose that \(\mathbf{u}\) and \(\mathbf{v}\) are vectors in 3-space and let θ be the angle between them then,</p>
</li>
</ul>
<p>\[ \parallel \mathbf{u \times v} \parallel = \parallel \mathbf{u} \parallel\parallel \mathbf{v} \parallel \sin\theta \]</p>
<h3 id="euclidean-inner-product"><a href="#euclidean-inner-product" class="headerlink" title="euclidean inner product"></a>euclidean inner product</h3><ul>
<li>Suppose \( \mathbf{u}=(u_1,u_2,…,u_n) \) and \( \mathbf{v} = (v_1,v_2,…,v_n) \) are two vectors in \( \mathbb{R}^n \) then the <strong>Euclidean inner product</strong> denoted by \( \mathbf{ u \centerdot v } \) is defined to be \( \mathbf{u \centerdot v} = u_1v_1 +u_2v_2 +…+u_nv_n \)</li>
</ul>
<h3 id="euclidean-norm"><a href="#euclidean-norm" class="headerlink" title="euclidean norm"></a>euclidean norm</h3><ul>
<li>Suppose \( \mathbf{u} = (u_1,u_2,…,u_n) \) is a vector in \( \mathbb{R}^n \) then the <strong>Euclidean norm</strong> is, \[ \parallel \mathbf{u} \parallel = (\mathbf{u \centerdot u})^{1 \over 2} = \sqrt{ u_1^2 + u_2^2 + … + u_n^2 } \]</li>
</ul>
<h3 id="euclidean-distance"><a href="#euclidean-distance" class="headerlink" title="euclidean distance"></a>euclidean distance</h3><ul>
<li><p>Suppose \( \mathbf{u}=(u_1,u_2,…,u_n) \)and \( \mathbf{v} =(v_1,v_2,…,v_n) \) are two points in \(\mathbb{R}^n\) then the <strong>Euclidean distance</strong> between them is defined to be, \[ d(\mathbf{u}, \mathbf{v}) = \parallel \mathbf{u-v} \parallel = \sqrt{(u_1-v_1)^2+(u_2-v_2)^2+…+(u_n-v_n)^2} \]</p>
</li>
<li><p>If \(\mathbf{u}\) and \(\mathbf{v}\) are two vectors in \(\mathbb{R}^n\) then, \[ \mathbf{u \centerdot v} = {1 \over 4} {\parallel \mathbf{u+v} \parallel}^2 - {1 \over 4} {\parallel \mathbf{u-v} \parallel}^2 \]</p>
</li>
<li><p>\( f: \mathbb{R}^n \rightarrow \mathbb{R}^m \) for example define \( T: \mathbb{R}^2 \rightarrow \mathbb{R}^4\) as, \[ T(x_1, x_2) = (3x_1-4x_2, x_1+2x_2, 6x_1-x_2, 10x_2) = \begin{bmatrix} 3 &amp; -4 \\ 1 &amp; 2 \\ 6 &amp; -1 \\ 0 &amp; 10 \end{bmatrix} \begin{bmatrix} x_1 \\ x_2\end{bmatrix} \Rightarrow \mathbf{w} = A\mathbf{x}  \]</p>
</li>
</ul>
<h3 id="linear-transformation"><a href="#linear-transformation" class="headerlink" title="linear transformation"></a>linear transformation</h3><ul>
<li>A function \( T: \mathbb{R}^n \rightarrow \mathbb{R}^m \) is called a <strong>linear transformation</strong> if for all \(\mathbf{u}\) and \(\mathbf{v}\) in \(\mathbb{R}^n\) and all scalars \(c\) we have, \[ T(\mathbf{u+v}) = T(\mathbf{u}) + T(\mathbf{v})  \] \[ T(c\mathbf{u}) = cT(\mathbf{u})  \]</li>
</ul>
<h3 id="induced-transformation"><a href="#induced-transformation" class="headerlink" title="induced transformation"></a>induced transformation</h3><ul>
<li>If A is an \(m \times n\) matrix then its <strong>induced transformation</strong>, \( T_A: \mathbb{R}^n \rightarrow \mathbb{R}^m \) defined as, \[ T_A(\mathbf{x}) = A\mathbf{x}  \] is a linear transformation.</li>
</ul>
<h3 id="matrix-induced-by-T"><a href="#matrix-induced-by-T" class="headerlink" title="matrix induced by T"></a>matrix induced by T</h3><ul>
<li>Let \( T: \mathbb{R}^n \rightarrow \mathbb{R}^m \) be a linear transformation, then there is an \(m \times n\) matrix such that \(T = T_A\) (recall that \(T_A\) is the transformation induced by \(A\)). The matrix \(A\) is called the <strong>matrix induced by \(T\)</strong> and is sometimes denoted as \(A = [T]\).</li>
</ul>
<h2 id="example-of-linear-transformations"><a href="#example-of-linear-transformations" class="headerlink" title="example of linear transformations"></a>example of linear transformations</h2><p>please refer to Paul Dawkins <a target="_blank" rel="noopener" href="http://tutuorial.math.lamar.edu/">http://tutuorial.math.lamar.edu/</a></p>
<h2 id="vector-spaces"><a href="#vector-spaces" class="headerlink" title="vector spaces"></a>vector spaces</h2><h3 id="linear-independence"><a href="#linear-independence" class="headerlink" title="linear independence"></a>linear independence</h3><ul>
<li><p>Suppose \( S = {\mathbf{v_1},\mathbf{v_2},…,\mathbf{v_n}} \) is a non-empty set of vectors and form the vector equation,<br>\[c_1\mathbf{v_1} +c_2\mathbf{v_2} + … +c_n\mathbf{v_n} =0\] This equation has at least one solution,namely, \(c_1 =0, c_2 =0,…, c_n =0\). This solution is called the <strong>trivial solution</strong>.</p>
<p>  If the trivial solution is the only solution to this equation then the vectors in the set S are called <strong>linearly independent</strong> and the set is called a <strong>linearly independent set</strong>. If there is another solution then the vectors in the set S are called <strong>linearly dependent</strong> and the set is called a <strong>linearly dependent set</strong>.</p>
</li>
<li><p>A finite set of vectors that contains the zero vector will be linearly dependent.</p>
</li>
<li><p>Suppose that \( S = {\mathbf{v_1},\mathbf{v_2},…,\mathbf{v_n}} \) is a set of vectors in \( \mathbb{R}^n\) . If k &gt; n then the<br>set of vectors is linearly dependent.</p>
</li>
</ul>
<h3 id="basis"><a href="#basis" class="headerlink" title="basis"></a>basis</h3><ul>
<li><p>Suppose \( S = {\mathbf{v_1},\mathbf{v_2},…,\mathbf{v_n}} \) is a set of vectors from the vector space <em>V</em>. Then S is called a <strong>basis</strong> (plural is <strong>bases</strong>) for <em>V</em> if both of the following conditions hold.</p>
<p>  (a) \(span(S)=V\), i.e. <em>S</em> spans the vector space <em>V</em>. </p>
<p>  (b) <em>S</em> is a linearly independent set of vectors.</p>
</li>
<li><p>Suppose that the set \( S = {\mathbf{v_1},\mathbf{v_2},…,\mathbf{v_n}} \) is a basis for the vector space <em>V</em> then<br>every vector <strong>u</strong> from <em>V</em> can be expressed as a linear combination of the vectors from <em>S</em> in exactly one way.</p>
</li>
</ul>
<h3 id="dimension"><a href="#dimension" class="headerlink" title="dimension"></a>dimension</h3><ul>
<li><p>Suppose that <strong>V</strong> is a non-zero vector space and that <strong>S</strong> is a set of vectors from <strong>V</strong> that for a basis for <strong>V</strong>. If <strong>S</strong> contains a finite number of vectors, say \( S = {\mathbf{v_1},\mathbf{v_2},…,\mathbf{v_n}} \),<br>then we call <em>V</em> a <strong>finite dimensional</strong> vector space and we say that the <strong>dimension</strong> of <em>V</em>, denoted by dim (<em>V</em> ) , is n (i.e. the number of basis elements in <em>S</em>. If <em>V</em> is not a finite<br>dimensional vector space (so S does not have a finite number of vectors) then we call it an <strong>infinite dimensional</strong> vector space.</p>
<p>  By definition the dimension of the zero vector space (i.e. the vector space consisting solely of the zero vector) is zero.</p>
</li>
<li><p>Suppose that <em>V</em> is a finite dimensional vector space with dim (<em>V</em> ) = <em>n</em> and that</p>
</li>
<li><p>S* is any finite set of vectors from <em>V</em>.</p>
<p>   (a) If <em>S</em> spans <em>V</em> but is not a basis for <em>V</em> then it can be reduced to a basis for <em>V</em> by<br>removing certain vectors from <em>S</em>.</p>
<p>   (b) If <em>S</em> is linearly independent but is not a basis <em>V</em> then it can be enlarged to a<br>basis for <em>V</em> by adding in certain vectors from <em>V</em>.</p>
</li>
</ul>
<h3 id="change-of-basis"><a href="#change-of-basis" class="headerlink" title="change of basis"></a>change of basis</h3><ul>
<li><p>Suppose that \( S = {\mathbf{v_1},\mathbf{v_2},…,\mathbf{v_n}} \) is a basis for a vector space <em>V</em> and that <strong>u</strong> is any vector from <em>V</em>. Since <strong>u</strong> is a vector in <em>V</em> it can be expressed as a linear combination of<br>the vectors from <em>S</em> as follows,<br>\[ \mathbf{u} = c_1\mathbf{v_1} +c_2\mathbf{v_2} + … +c_n\mathbf{v_n} \]<br>The scalars \( c_1,c_2,…,c_n \) are called the <strong>coordinates</strong> of u relative to the basis <em>S</em>. The <strong>coordinate vectors of u relative to</strong> <strong><em>S</em></strong> is denoted by \( (u)_S \) and defined to be the following vector in \( \mathbb{R}^n \), \[ (\mathbf{u})_S =(c_1,c_2,…,c_n) \]</p>
</li>
<li><p>Suppose that <em>V</em> is a n-dimensional vector space and further suppose that \( B ={\mathbf{v_1},\mathbf{v_2},…,\mathbf{v_n}} \) and \( C ={\mathbf{w_1},\mathbf{w_2},…,\mathbf{w_n}} \) are two bases for <em>V</em>. The <strong>transition matrix</strong> from <em>C</em> to <em>B</em> is defined to be,</p>
</li>
</ul>
<p>\[ P = [[\mathbf{w_1}_B]|[\mathbf{w_2}_B]|…|[\mathbf{w_n}_B]] \]</p>
<p>where the \(i^th\) column of <em>P</em> is the coordinate matrix of \(\mathbf{w_i}\) relative to <em>B</em>.</p>
<p>The coordinate matrix of a vector <strong>u</strong> in <em>V</em>, relative to <em>B</em>, is then related to the coordinate matrix of <strong>u</strong> relative to <em>C</em> by the following equation.<br>\[ {[\mathbf{u}]}_B =P{[\mathbf{u}]}_C \]</p>
<ul>
<li><p>Suppose that <em>V</em> is a finite dimensional vector space and that <em>P</em> is the transition matrix from <em>C</em> to <em>B</em> then,</p>
<p>  (a) <em>P</em> is invertible and,</p>
<p>  (b) \(P^{−1}\) is the transition matrix from <em>B</em> to <em>C</em>.</p>
</li>
</ul>
<h3 id="fundamental-subspaces"><a href="#fundamental-subspaces" class="headerlink" title="fundamental subspaces"></a>fundamental subspaces</h3><ul>
<li><p>The <strong>row vectors</strong> (we called them row matrices at the time) are the vectors in \(\mathbb{R}^m\) formed out of the rows of <em>A</em>. The <strong>column vectors</strong> (again we called them column matrices at the time) are the vectors in \(\mathbb{R}^n\) that are formed out of the columns of <em>A</em>.</p>
</li>
<li><p>Suppose that <em>A</em> is an <em>n × m</em> matrix.</p>
<p>  (a) The subspace of \(\mathbb{R}^m\) that is spanned by the row vectors of <em>A</em> is called the <strong>row space</strong> of <em>A</em>.</p>
<p>  (b) The subspace of \(\mathbb{R}^n\) that is spanned by the column vectors of <em>A</em> is called the <strong>column space</strong> of <em>A</em>.</p>
</li>
<li><p>The dimension of the null space of <em>A</em> is called the <strong>nullity</strong> of <em>A</em> and is denoted by nullity(<em>A</em>).</p>
</li>
<li><p>Suppose that <em>A</em> is a matrix and <em>U</em> is a matrix in row-echelon form that has been obtained by performing row operations on <em>A</em>. Then the row space of <em>A</em> and the row space of <em>U</em> are the same space.</p>
</li>
<li><p>Suppose that <em>A</em> and <em>B</em> are two row equivalent matrices (so we got from one to the other by row operations) then a set of column vectors from <em>A</em> will be a basis for the column space of <em>A</em> if and only if the corresponding columns from <em>B</em> will form a basis for the column space of <em>B</em>.</p>
</li>
</ul>
<h3 id="rank"><a href="#rank" class="headerlink" title="rank"></a>rank</h3><ul>
<li><p>Suppose that <em>A</em> is a matrix then the row space of <em>A</em> and the column space of <em>A</em> will have the same dimension. We call this common dimension the <strong>rank</strong> of A and denote it by rank(<em>A</em>).</p>
</li>
<li><p>Let A be an <em>n × n</em> matrix. The following statements are equivalent.</p>
<p>  (a) <em>A</em> is invertible.</p>
<p>  (b) The only solution to the system \(A\mathbf{x} = 0 \) is the trivial solution. </p>
<p>  (c) <em>A</em> is row equivalent to \(I_n\) .</p>
<p>  (d) <em>A</em> is expressible as a product of elementary matrices.</p>
<p>  (e) \(A\mathbf{x} = \mathbf{b} \) has exactly one solution for every <em>n ×1</em> matrix <strong>b</strong>.</p>
<p>  (f) \(A\mathbf{x} = \mathbf{b} \) is consistent for every <em>n ×1</em> matrix <strong>b</strong>.</p>
<p>  (g) \( det(A) \neq 0\)</p>
<p>  (h) The null space of A is {0}, i.e. just the zero vector. </p>
<p>  (i) nullity(<em>A</em>)=0.</p>
<p>  (j) rank(<em>A</em>)=<em>n</em>.</p>
<p>  (k) The columns vectors of <em>A</em> form a basis for \(\mathbb{R}^n\). </p>
<p>  (l) The row vectors of <em>A</em> form a basis for \(\mathbb{R}^n\).</p>
</li>
</ul>
<h3 id="inner-product"><a href="#inner-product" class="headerlink" title="inner product"></a>inner product</h3><ul>
<li><p>Suppose <strong>u</strong>, <strong>v</strong>, and <strong>w</strong> are all vectors in a vector space <em>V</em> and <em>c</em> is any scalar. An <strong>inner product</strong> on the vector space <em>V</em> is a function that associates with each pair of<br>vectors in <em>V</em>, say <strong>u</strong> and <strong>v</strong>, a real number \( &lt;\mathbf{u,v}&gt; \)that satisfies the following denoted by axioms.</p>
<p>  (a) \( &lt;\mathbf{u,v}&gt; = &lt;\mathbf{v,u}&gt; \)</p>
<p>  (b) \( &lt;\mathbf{u+v,w}&gt; = &lt;\mathbf{u,w}&gt; + &lt;\mathbf{v,w}&gt; \)</p>
<p>  (c) \( &lt; {c}\mathbf{u,v}&gt; = {c}&lt;\mathbf{u,v}&gt; \)</p>
<p>  (d) \( &lt;\mathbf{u,u}&gt; \geq 0 \) and \( &lt;\mathbf{u,u}&gt; =0 \) if and only if <strong>u</strong>=0</p>
<p>  A vector space along with an inner product is called an <strong>inner product space</strong>.</p>
</li>
<li><p>Suppose that <strong>u</strong> and <strong>v</strong> are two vectors in an inner product space. They are said to be <strong>orthogonal</strong> if \( &lt;\mathbf{u,v}&gt; =0 \).</p>
</li>
</ul>
<h3 id="orthogonal-complements"><a href="#orthogonal-complements" class="headerlink" title="orthogonal complements"></a>orthogonal complements</h3><ul>
<li><p>Suppose that <em>W</em> is a subspace of an inner product space <em>V</em>. We say that a vector <strong>u</strong> from <em>V</em> is <strong>orthogonal to W</strong> if it is orthogonal to every vector in <em>W</em>. The set of all vectors that are orthogonal to <em>W</em> is called the <strong>orthogonal complement of</strong> <strong><em>W</em></strong> and is denoted by \( W^{\bot} \).</p>
<p>  We say that <em>W</em> and \( W^{\bot} \) are <strong>orthogonal complements</strong>.</p>
</li>
<li><p>Suppose <em>W</em> is a subspace of an inner product space <em>V</em>. Then, </p>
<p>  (a) \( W^{\bot} \) is a subspace of <em>V</em>.</p>
<p>  (b) Only the zero vector, <strong>0</strong>, is common to both <em>W</em> and \( W^{\bot} \) .</p>
<p>  (c) \( {(W^{\bot})}^{\bot} = W \) . Or in other words, the orthogonal complement of \( W^{\bot} \) is W.</p>
</li>
</ul>
<h3 id="orthogonal-basis"><a href="#orthogonal-basis" class="headerlink" title="orthogonal basis"></a>orthogonal basis</h3><ul>
<li><p>Suppose that <em>S</em> is a set of vectors in an inner product space.</p>
<p>  (a) If each pair of distinct vectors from <em>S</em> is orthogonal then we call <em>S</em> an <strong>orthogonal set</strong>.</p>
<p>  (b) If <em>S</em> is an orthogonal set and each of the vectors in <em>S</em> also has a norm of 1 then we call <em>S</em> an <strong>orthonormal set</strong>.</p>
</li>
<li><p>Suppose that \( S ={ \mathbf{v_1}, \mathbf{v_2},… ,\mathbf{v_n}} \) is an orthogonal basis for an inner product space and that <strong>u</strong> is any vector from the inner product space then,</p>
</li>
</ul>
<p>\[ \mathbf{u} =  { &lt; \mathbf{u,v_1} &gt;  \over {\parallel \mathbf{v_1} \parallel}^2 } \mathbf{v_1} + { &lt; \mathbf{u,v_2} &gt;  \over {\parallel \mathbf{v_2} \parallel}^2 } \mathbf{v_2} + … + { &lt; \mathbf{u,v_n} &gt;  \over {\parallel \mathbf{v_n} \parallel}^2 } \mathbf{v_n}\]</p>
<p>If in addition <em>S</em> is in fact an orthonormal basis then,</p>
<p>\[ \mathbf{u} = &lt;\mathbf{u,v_1}&gt;\mathbf{v_1} + &lt;\mathbf{u,v_2}&gt;\mathbf{v_2} + … + &lt;\mathbf{u,v_n}&gt;\mathbf{v_n}  \]</p>
<h3 id="Gram-Schmidt-Porcess"><a href="#Gram-Schmidt-Porcess" class="headerlink" title="Gram-Schmidt Porcess"></a>Gram-Schmidt Porcess</h3><p>Suppose that <em>V</em> is a finite dimensional inner product space and that \( {\mathbf{v_1},\mathbf{v_2},…,\mathbf{v_n}} \) is a basis for <em>V</em> then an orthogonal basis for <em>V</em>, \( {\mathbf{u_1},\mathbf{u_2},…,\mathbf{u_n}} \), can be found using the following process.</p>
<p>\[ \mathbf{u_1} = \mathbf{v_1} \]</p>
<p>\[ \mathbf{u_2} = \mathbf{v_2} - {&lt;\mathbf{v_2, u_1}&gt; \over {\parallel \mathbf{u_1} \parallel}^2}\mathbf{u_1} \]</p>
<p>\[ \mathbf{u_3} = \mathbf{v_3} - {&lt;\mathbf{v_3, u_1}&gt; \over {\parallel \mathbf{u_1} \parallel}^2}\mathbf{u_1} -  {&lt;\mathbf{v_3, u_2}&gt; \over {\parallel \mathbf{u_2} \parallel}^2}\mathbf{u_2} \]</p>
<p>\[    \vdots      \vdots   \]</p>
<p>\[ \mathbf{u_n} = \mathbf{v_n} - {&lt;\mathbf{v_n, u_1}&gt; \over {\parallel \mathbf{u_1} \parallel}^2}\mathbf{u_1} - {&lt;\mathbf{v_n, u_2}&gt; \over {\parallel \mathbf{u_2} \parallel}^2}\mathbf{u_2} - {&lt;\mathbf{v_n, u_3}&gt; \over {\parallel \mathbf{u_3} \parallel}^2}\mathbf{u_3} - … \]</p>
<p>To convert the basis to an orthonormal basis simply divide all the new basis vectors by their norm. Also, due to the construction process we have</p>
<p>\[ span(\mathbf{u_1},\mathbf{u_2},…,\mathbf{u_k}) = span(\mathbf{v_1},\mathbf{v_2},…,\mathbf{v_k}) \] for \[k =1,2,…,n \]</p>
<p>and \(u_k \) will be orthogonal to </p>
<p>\( span( v1, …,v_{k−1}) \) for \( k=2,3,…n. \)</p>
</div><div class="tags"><a href="/tags/cheating-sheet/"><i class="fa fa-tag"></i>cheating sheet</a></div><div class="post-nav"><a class="pre" href="/2018/03/22/working-with-math-equations-in-hexo-next-theme/">working with math equations in hexo next theme</a><a class="next" href="/2018/03/21/hexo-categories-tags-404-issue-on-github/">hexo categories/tags 404 issue on github</a></div><div id="disqus_thread"><div class="btn_click_load"><button class="disqus_click_btn">阅读评论（请确保 Disqus 可以正常加载）</button></div><script type="text/javascript">var disqus_config = function () {
    this.page.url = 'http://example.com/2018/03/22/linear-algebra-cheating-sheet/';
    this.page.identifier = '2018/03/22/linear-algebra-cheating-sheet/';
    this.page.title = 'linear algebra cheating sheet';
  };</script><script type="text/javascript" id="disqus-lazy-load-script">$.ajax({
url: 'https://disqus.com/next/config.json',
timeout: 2500,
type: 'GET',
success: function(){
  var d = document;
  var s = d.createElement('script');
  s.src = '//joejztang.disqus.com/embed.js';
  s.setAttribute('data-timestamp', + new Date());
  (d.head || d.body).appendChild(s);
  $('.disqus_click_btn').css('display', 'none');
},
error: function() {
  $('.disqus_click_btn').css('display', 'block');
}
});</script><script type="text/javascript" id="disqus-click-load">$('.btn_click_load').click(() => {  //click to load comments
    (() => { // DON'T EDIT BELOW THIS LINE
        var d = document;
        var s = d.createElement('script');
        s.src = '//joejztang.disqus.com/embed.js';
        s.setAttribute('data-timestamp', + new Date());
        (d.head || d.body).appendChild(s);
    })();
    $('.disqus_click_btn').css('display','none');
});</script><script type="text/javascript" id="disqus-count-script">$(function() {
     var xhr = new XMLHttpRequest();
     xhr.open('GET', '//disqus.com/next/config.json', true);
     xhr.timeout = 2500;
     xhr.onreadystatechange = function () {
       if (xhr.readyState === 4 && xhr.status === 200) {
         $('.post-meta .post-comments-count').show();
         var s = document.createElement('script');
         s.id = 'dsq-count-scr';
         s.src = 'https://joejztang.disqus.com/count.js';
         s.async = true;
         (document.head || document.body).appendChild(s);
       }
     };
     xhr.ontimeout = function () { xhr.abort(); };
     xhr.send(null);
   });
</script></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"/><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Categories</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/alg-summary/">Alg summary</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/alison-photography/">Alison photography</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/c/">C#</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/dp/">DP</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/django/">Django</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/hexo/">Hexo</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/java/">Java</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/math/">Math</a><span class="category-list-count">2</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/math/linear-algebra/">Linear Algebra</a><span class="category-list-count">2</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/r/">R</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/sql-server/">SQL Server</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/scrapy/">Scrapy</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/selfnotes/">SelfNotes</a><span class="category-list-count">30</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/unit-test/">Unit Test</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/apache-beam/">apache beam</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/big-data/">big data</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cheat-sheet/">cheat sheet</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/css/">css</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/data-structure/">data structure</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/database/">database</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/deep-learning/">deep learning</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/elasticsearch/">elasticsearch</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/flask/">flask</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/git/">git</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/graph/">graph</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/hexo/">hexo</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/javascript/">javascript</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/jenkins/">jenkins</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/language-common/">language common</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/linear-algebra/">linear algebra</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/linux/">linux</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/machine-learning/">machine learning</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/nodejs/">nodejs</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/pandas/">pandas</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/photoshop/">photoshop</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/php/">php</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/python/">python</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/reactjs/">reactjs</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/security/">security</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/server/">server</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/spark/">spark</a><span class="category-list-count">1</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/recommender-system/" style="font-size: 15px;">recommender system</a> <a href="/tags/python/" style="font-size: 15px;">python</a> <a href="/tags/https/" style="font-size: 15px;">https</a> <a href="/tags/cheat-sheet/" style="font-size: 15px;">cheat sheet</a> <a href="/tags/logging/" style="font-size: 15px;">logging</a> <a href="/tags/conda/" style="font-size: 15px;">conda</a> <a href="/tags/venv/" style="font-size: 15px;">venv</a> <a href="/tags/unittest/" style="font-size: 15px;">unittest</a> <a href="/tags/cheating-sheet/" style="font-size: 15px;">cheating sheet</a> <a href="/tags/recursion/" style="font-size: 15px;">recursion</a> <a href="/tags/cte/" style="font-size: 15px;">CTE</a> <a href="/tags/sql-server/" style="font-size: 15px;">SQL Server</a> <a href="/tags/linux/" style="font-size: 15px;">linux</a> <a href="/tags/keras/" style="font-size: 15px;">keras</a> <a href="/tags/tensorflow/" style="font-size: 15px;">tensorflow</a> <a href="/tags/elk/" style="font-size: 15px;">elk</a> <a href="/tags/google-cloud/" style="font-size: 15px;">google cloud</a> <a href="/tags/graph-theory/" style="font-size: 15px;">graph theory</a> <a href="/tags/hexo-404-issue/" style="font-size: 15px;">hexo 404 issue</a> <a href="/tags/seo/" style="font-size: 15px;">seo</a> <a href="/tags/hexo-%E4%BC%98%E5%8C%96/" style="font-size: 15px;">hexo 优化</a> <a href="/tags/kubernetes/" style="font-size: 15px;">kubernetes</a> <a href="/tags/java-io/" style="font-size: 15px;">Java IO</a> <a href="/tags/java-8-streams/" style="font-size: 15px;">java 8 streams</a> <a href="/tags/java-lambda/" style="font-size: 15px;">java lambda</a> <a href="/tags/alg/" style="font-size: 15px;">alg</a> <a href="/tags/binary-search/" style="font-size: 15px;">binary search</a> <a href="/tags/pandas/" style="font-size: 15px;">pandas</a> <a href="/tags/photography/" style="font-size: 15px;">photography</a> <a href="/tags/php-tools/" style="font-size: 15px;">php tools</a> <a href="/tags/debug-trick/" style="font-size: 15px;">debug trick</a> <a href="/tags/heapq/" style="font-size: 15px;">heapq</a> <a href="/tags/circular-imports/" style="font-size: 15px;">circular imports</a> <a href="/tags/mock/" style="font-size: 15px;">mock</a> <a href="/tags/pytest/" style="font-size: 15px;">pytest</a> <a href="/tags/react-redux/" style="font-size: 15px;">react-redux</a> <a href="/tags/javascript/" style="font-size: 15px;">javascript</a> <a href="/tags/react/" style="font-size: 15px;">react</a> <a href="/tags/apache/" style="font-size: 15px;">apache</a> <a href="/tags/redux/" style="font-size: 15px;">redux</a> <a href="/tags/regular-expression/" style="font-size: 15px;">regular expression</a> <a href="/tags/python3/" style="font-size: 15px;">python3</a> <a href="/tags/template/" style="font-size: 15px;">template</a> <a href="/tags/java-8-io/" style="font-size: 15px;">Java 8 IO</a> <a href="/tags/idea/" style="font-size: 15px;">idea</a> <a href="/tags/whim/" style="font-size: 15px;">whim</a> <a href="/tags/hexo-math-equations/" style="font-size: 15px;">hexo math equations</a> <a href="/tags/jenkins/" style="font-size: 15px;">jenkins</a> <a href="/tags/amazon/" style="font-size: 15px;">amazon</a> <a href="/tags/tag/" style="font-size: 15px;">tag</a> <a href="/tags/dp/" style="font-size: 15px;">dp</a> <a href="/tags/ood/" style="font-size: 15px;">ood</a> <a href="/tags/epic/" style="font-size: 15px;">Epic</a> <a href="/tags/sql/" style="font-size: 15px;">sql</a> <a href="/tags/frequent/" style="font-size: 15px;">frequent</a> <a href="/tags/backtracking/" style="font-size: 15px;">backtracking</a> <a href="/tags/inversion-count/" style="font-size: 15px;">inversion count</a> <a href="/tags/code/" style="font-size: 15px;">code</a> <a href="/tags/tbd/" style="font-size: 15px;">tbd</a> <a href="/tags/google/" style="font-size: 15px;">google</a> <a href="/tags/linkedlist/" style="font-size: 15px;">linkedlist</a> <a href="/tags/sliding-window/" style="font-size: 15px;">sliding window</a> <a href="/tags/tree/" style="font-size: 15px;">tree</a> <a href="/tags/%E9%9D%A2%E8%AF%95%E9%AB%98%E9%A2%91/" style="font-size: 15px;">面试高频</a> <a href="/tags/bfs/" style="font-size: 15px;">BFS</a> <a href="/tags/dfs/" style="font-size: 15px;">DFS</a> <a href="/tags/two-pointer/" style="font-size: 15px;">two pointer</a> <a href="/tags/rabin-karp/" style="font-size: 15px;">rabin-karp</a> <a href="/tags/graph/" style="font-size: 15px;">graph</a> <a href="/tags/stack/" style="font-size: 15px;">stack</a> <a href="/tags/bst/" style="font-size: 15px;">BST</a> <a href="/tags/twitter/" style="font-size: 15px;">twitter</a> <a href="/tags/iterative/" style="font-size: 15px;">iterative</a> <a href="/tags/two-pointers/" style="font-size: 15px;">two pointers</a> <a href="/tags/ood/" style="font-size: 15px;">OOD</a> <a href="/tags/io/" style="font-size: 15px;">io</a> <a href="/tags/object-oriented-design/" style="font-size: 15px;">Object Oriented Design</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2022/03/29/code/52-NQueens-II/">52. N-Queens II</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/03/29/code/126-word-ladder-ii/">126. word ladder ii</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/03/28/code/51-NQueens/">51. N-Queens</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/03/28/code/127-word-ladder/">127. word ladder</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/03/27/code/364-Nested-List-Weight-Sum-II/">364. Nested List Weight Sum II</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/03/27/code/286-Walls-and-Gates/">286. Walls and Gates</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/03/27/code/130-Surrounded-Regions/">130. Surrounded Regions</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/03/27/code/339-Nested-List-Weight-Sum/">339. Nested List Weight Sum</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/03/27/code/200-Number-of-Islands/">200. Number of Islands</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/03/26/code/341-Flatten-Nested-List-Iterator/">341. Flatten Nested List Iterator</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-comment-o"> Recent Comments</i></div><script type="text/javascript" src="//joejztang.disqus.com/recent_comments_widget.js?num_items=5&amp;hide_avatars=1&amp;avatar_size=32&amp;excerpt_length=20&amp;hide_mods=1"></script></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2022 <a href="/." rel="nofollow">130L blog.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.css"><link rel="stylesheet" type="text/css" href="/css/search.css?v=0.0.0"><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/js/copycode.js" successtext="Copy Successed!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>